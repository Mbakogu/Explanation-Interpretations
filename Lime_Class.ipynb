{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from collections import defaultdict\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"/Users/mbakogu/Desktop/Academics/AIML_Research_Sameer_Singh/Adult/adult.data\", delimiter=', ', dtype = str)\n",
    "classifier = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer\n",
    "feature_names = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital Status\",\"Occupation\", \n",
    "                 \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\"Hours per week\", \"Country\"]\n",
    "\n",
    "categorical_features = [1,3,5,6,7,8,9,13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateExplanations():\n",
    "    \n",
    "    def __init__(self, data, classifier, explainer, feature_names = [], categorical_features = [], train_percentage = 0.80):\n",
    "        \"\"\"\n",
    "        data: n columns consisting of n-1 column features followed by 1 column classification\n",
    "        \n",
    "        classifier: any initialized classifier\n",
    "        e.g.: xgboost.XGBClassifier(n_estimators=300, max_depth=5)\n",
    "        \n",
    "        explainer: uninitiated explainer\n",
    "        e.g.: lime.lime_tabular.LimeTabularExplainer\n",
    "        \n",
    "        feature_names: optional list representing names of each feature (excluding classification); integers \n",
    "        used if omitted\n",
    "        e.g.: [name, gender, age, money] corresponds to features 0-3 in data\n",
    "        \n",
    "        categorical_features = denotes which features, by index, are categorical data\n",
    "        e.g.: [2,7,9] notes that features in column 2,7, and 9 are categorical\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = data[:,:]\n",
    "        self.classifier = classifier\n",
    "        self.categorical_features = categorical_features\n",
    "        if feature_names == []:\n",
    "            feature_names = [str(x) for x in range(len(self.data[0,:-1]))]\n",
    "            \n",
    "        self.labels = self.data[:,len(self.data[0,:])-1]\n",
    "        self.data = self.data[:,:-1] \n",
    "        class_names = set(self.labels)\n",
    "        categorical_names = {}     \n",
    "        \n",
    "        if data.dtype != \"float64\":\n",
    "            le = sklearn.preprocessing.LabelEncoder()\n",
    "            le.fit(self.labels)\n",
    "            self.labels = le.transform(self.labels)\n",
    "            class_names = le.classes_\n",
    "            \n",
    "            self.data, categorical_names = self.process_data(self.data)\n",
    "            \n",
    "        self.data = self.data.astype(float)\n",
    "        \n",
    "        self.encoder = sklearn.preprocessing.OneHotEncoder(categorical_features=self.categorical_features)\n",
    "                  \n",
    "        self.train, self.test, self.labels_train, self.labels_test = sklearn.model_selection.train_test_split(self.data, self.labels, \n",
    "                                                                        train_size=train_percentage, test_size=1-train_percentage)\n",
    "        \n",
    "        self.encoder.fit(self.data)\n",
    "        \n",
    "        encoded_train = self.encoder.transform(self.train)\n",
    "        \n",
    "        self.classifier.fit(encoded_train, self.labels_train)\n",
    "        \n",
    "        self.explainer = explainer(self.train, feature_names = feature_names, class_names=class_names,\n",
    "                                                   categorical_features=self.categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3)\n",
    "        \n",
    "                \n",
    "        self.train_standard = np.array(self.normalize(self.train))\n",
    "        self.test_standard = np.array(self.normalize(self.test))\n",
    "  \n",
    "                \n",
    "    def normalize(self, data):\n",
    "        normalized_data = [[0 for x in range(len(data[0,:]))] for x in range(len(data[:,0]))]\n",
    "        \n",
    "        for col in range(len(data[0,:])):\n",
    "            total = 0\n",
    "            for item in range(len(data[:,col])):\n",
    "                total += abs(data[item,col])\n",
    "                \n",
    "            if total == 0:\n",
    "                total = 1\n",
    "                \n",
    "            for item in range(len(data[:,col])):\n",
    "                normalized_data[item][col] = float(abs(data[item,col]))/total\n",
    "                \n",
    "        return normalized_data\n",
    "        \n",
    "\n",
    "    def process_data(self, data):\n",
    "        categorical_names = {}\n",
    "        for i in self.categorical_features:\n",
    "            le = sklearn.preprocessing.LabelEncoder()\n",
    "            le.fit(data[:, i])\n",
    "            data[:, i] = le.transform(data[:, i])\n",
    "            categorical_names[i] = le.classes_\n",
    "            \n",
    "        return data, categorical_names\n",
    "           \n",
    "    def classify_accuracy(self, test_data, test_labels):\n",
    "        sklearn.metrics.accuracy_score(test_labels, self.classifier.predict(self.encoder.transform(test_data)))\n",
    "        \n",
    "    def predict(self, instance):\n",
    "        return self.classifier.predict_proba(self.encoder.transform(instance)).astype(float)\n",
    "        \n",
    "    def explain_with_lime(self, instance, num_features):\n",
    "        return self.explainer.explain_instance(instance, self.predict, num_features=num_features).as_list()\n",
    "    \n",
    "    def k_cluster(self, data = None, k = 2, func = None):\n",
    "        print(\"Kmeans for {} clusters\".format(k))\n",
    "        if data is None:\n",
    "            data = self.test_standard\n",
    "        \n",
    "        if func is None:\n",
    "            means = KMeans(n_clusters=k, random_state=0).fit_predict(data)\n",
    "            return means\n",
    "        \n",
    "        return func(data)\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gener = GenerateExplanations(data, classifier, explainer, feature_names, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = np.array(gener.test)\n",
    "instances_standard = np.array(gener.test_standard)\n",
    "labels = np.array(gener.labels_test)\n",
    "explanations = []\n",
    "explanations_standard = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(len(instances)):\n",
    "    explanations.append(gener.explain_with_lime(instances[item],14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(len(instances_standard)):\n",
    "    explanations_standard.append(gener.explain_with_lime(instances[item],14))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(len(explanations)):\n",
    "    for ele in range(len(explanations[item])):\n",
    "        explanations[item][ele] = float(explanations[item][ele][1])\n",
    "\n",
    "for item in range(len(explanations_standard)):\n",
    "    for ele in range(len(explanations_standard[item])):\n",
    "        explanations_standard[item][ele] = float(explanations_standard[item][ele][1])\n",
    "\n",
    "explanations_standard = np.array(gener.normalize(np.array(explanations_standard)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
